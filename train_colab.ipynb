{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üì° XAI Semantic Communication - Training sur Colab\n",
                "\n",
                "Ce notebook entra√Æne le mod√®le JSCC sur COCO (118k images) avec A100.\n",
                "\n",
                "**Pr√©requis :**\n",
                "- Dataset COCO dans `/content/drive/MyDrive/CocoData/train2017/`\n",
                "- Runtime GPU A100 activ√©"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuration de l'environnement"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# V√©rifier le GPU\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Monter Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# V√©rifier le dataset COCO\n",
                "import os\n",
                "coco_path = '/content/drive/MyDrive/CocoData/train2017'\n",
                "if os.path.exists(coco_path):\n",
                "    n_images = len([f for f in os.listdir(coco_path) if f.endswith('.jpg')])\n",
                "    print(f\"‚úÖ Dataset COCO trouv√© : {n_images} images\")\n",
                "else:\n",
                "    print(\"‚ùå Dataset non trouv√© ! Ex√©cutez la cellule de t√©l√©chargement ci-dessous.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. (Optionnel) T√©l√©charger COCO si pas encore fait"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# D√©commenter pour t√©l√©charger COCO (~18 Go, 15-20 min)\n",
                "# !wget -q --show-progress http://images.cocodataset.org/zips/train2017.zip -O /content/train2017.zip\n",
                "# !unzip -q /content/train2017.zip -d /content/drive/MyDrive/CocoData/\n",
                "# !rm /content/train2017.zip"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Cloner le projet depuis GitHub"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Chemin du projet sur Drive (persistant)\n",
                "DRIVE_PROJECT = '/content/drive/MyDrive/semantic_comm'\n",
                "\n",
                "# Si le projet n'existe pas encore sur Drive, le cloner depuis GitHub\n",
                "if not os.path.exists(DRIVE_PROJECT):\n",
                "    print(\"üì• Clonage du projet depuis GitHub...\")\n",
                "    !git clone https://github.com/halidou02/Compression-d-image-avec-AE-et-XAI.git {DRIVE_PROJECT}\n",
                "    print(\"‚úÖ Projet clon√© sur Drive !\")\n",
                "else:\n",
                "    print(\"‚úÖ Projet d√©j√† pr√©sent sur Drive\")\n",
                "    # Optionnel : mettre √† jour depuis GitHub\n",
                "    # !cd {DRIVE_PROJECT} && git pull"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Aller dans le dossier du projet\n",
                "%cd {DRIVE_PROJECT}\n",
                "!ls -la"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Installer les d√©pendances\n",
                "!pip install -q torch torchvision tqdm pillow"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Configuration des chemins"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Cr√©er les dossiers de sauvegarde\n",
                "os.makedirs('checkpoints', exist_ok=True)\n",
                "os.makedirs('results/noskip', exist_ok=True)\n",
                "\n",
                "print(\"‚úÖ Dossiers cr√©√©s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Patch du chemin dataset dans train_noskip.py\n",
                "train_file = 'src/train/train_noskip.py'\n",
                "\n",
                "with open(train_file, 'r') as f:\n",
                "    content = f.read()\n",
                "\n",
                "# Remplacer le chemin du dataset\n",
                "old_path = \"root_dir=str(project_root.parent / 'CocoData')\"\n",
                "new_path = \"root_dir='/content/drive/MyDrive/CocoData/train2017'\"\n",
                "\n",
                "if old_path in content:\n",
                "    content = content.replace(old_path, new_path)\n",
                "    with open(train_file, 'w') as f:\n",
                "        f.write(content)\n",
                "    print(\"‚úÖ Chemin dataset mis √† jour\")\n",
                "else:\n",
                "    print(\"‚ÑπÔ∏è Chemin d√©j√† configur√© ou diff√©rent\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Lancer l'entra√Ænement"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entra√Ænement avec batch_size=32 (A100 peut g√©rer plus)\n",
                "!python -m src.train.train_noskip --batch_size 32 --epochs 100 --lr 2e-4"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Reprendre l'entra√Ænement (si interrompu)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Si la session a √©t√© interrompue, relancer avec --resume\n",
                "!python -m src.train.train_noskip --batch_size 32 --epochs 100 --lr 2e-4 --resume"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Visualiser les m√©triques"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Charger les m√©triques\n",
                "df = pd.read_csv('results/noskip/metrics.csv')\n",
                "print(df.tail(10))\n",
                "\n",
                "# Graphiques\n",
                "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
                "\n",
                "axes[0, 0].plot(df['epoch'], df['grid_avg_psnr'])\n",
                "axes[0, 0].set_title('Grid PSNR')\n",
                "axes[0, 0].set_xlabel('Epoch')\n",
                "axes[0, 0].set_ylabel('dB')\n",
                "\n",
                "axes[0, 1].plot(df['epoch'], df['grid_avg_ssim'])\n",
                "axes[0, 1].set_title('Grid SSIM')\n",
                "axes[0, 1].set_xlabel('Epoch')\n",
                "\n",
                "axes[1, 0].plot(df['epoch'], df['train_budget'])\n",
                "axes[1, 0].set_title('Budget Loss')\n",
                "axes[1, 0].set_xlabel('Epoch')\n",
                "\n",
                "axes[1, 1].plot(df['epoch'], df['mono_score'])\n",
                "axes[1, 1].set_title('Mono Score')\n",
                "axes[1, 1].set_xlabel('Epoch')\n",
                "axes[1, 1].set_ylim([0, 1.1])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('training_curves.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. V√©rifier les checkpoints"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!ls -lh checkpoints/\n",
                "print(\"\\n‚úÖ Tous les fichiers sont sur Drive et persistants !\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "A100",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}